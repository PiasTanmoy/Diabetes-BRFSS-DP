{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression as IR\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, \\\n",
    "                            average_precision_score, accuracy_score, \\\n",
    "                            balanced_accuracy_score, roc_auc_score, \\\n",
    "                            matthews_corrcoef\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, \\\n",
    "    ConfusionMatrixDisplay, PrecisionRecallDisplay, roc_curve, auc\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 22})\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tanmoysarkar/Trustworthiness/SEER/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/raid/home/tanmoysarkar/Trustworthiness/Diabetes - Paper/Gender Disparity in Diabetes'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200136, 30) (210874, 30) (238130, 30) (220390, 30)\n",
      "(200136, 49) (210874, 49) (238130, 49) (220390, 49)\n",
      "(200136, 50) (210874, 50) (238130, 50) (220390, 50)\n"
     ]
    }
   ],
   "source": [
    "brfss_2021_mapped_cat = pd.read_csv('BRFSS Datasets - Cleaned/Mapped categories (Step 2)/BRFSS 2021.csv')\n",
    "\n",
    "brfss_2021_mapped_cat['Race'] = brfss_2021_mapped_cat['Race'].replace({1: 'White', 2: 'Black', 3: 'American Indian',\n",
    "                                                               4: 'Asian', 5: 'Native Hawaiian', 6: 'Other race',\n",
    "                                                               7: 'Multiracial', 8: 'Hispanic'})\n",
    "\n",
    "brfss_2019_mapped_cat = pd.read_csv('BRFSS Datasets - Cleaned/Mapped categories (Step 2)/BRFSS 2019.csv')\n",
    "\n",
    "brfss_2019_mapped_cat['Race'] = brfss_2019_mapped_cat['Race'].replace({1: 'White', 2: 'Black', 3: 'American Indian',\n",
    "                                                               4: 'Asian', 5: 'Native Hawaiian', 6: 'Other race',\n",
    "                                                               7: 'Multiracial', 8: 'Hispanic'})\n",
    "\n",
    "brfss_2017_mapped_cat = pd.read_csv('BRFSS Datasets - Cleaned/Mapped categories (Step 2)/BRFSS 2017.csv')\n",
    "\n",
    "brfss_2017_mapped_cat['Race'] = brfss_2017_mapped_cat['Race'].replace({1: 'White', 2: 'Black', 3: 'American Indian',\n",
    "                                                               4: 'Asian', 5: 'Native Hawaiian', 6: 'Other race',\n",
    "                                                               7: 'Multiracial', 8: 'Hispanic'})\n",
    "\n",
    "brfss_2015_mapped_cat = pd.read_csv('BRFSS Datasets - Cleaned/Mapped categories (Step 2)/BRFSS 2015.csv')\n",
    "\n",
    "brfss_2015_mapped_cat['Race'] = brfss_2015_mapped_cat['Race'].replace({1: 'White', 2: 'Black', 3: 'American Indian',\n",
    "                                                               4: 'Asian', 5: 'Native Hawaiian', 6: 'Other race',\n",
    "                                                               7: 'Multiracial', 8: 'Hispanic'})\n",
    "\n",
    "print(brfss_2021_mapped_cat.shape, brfss_2019_mapped_cat.shape, brfss_2017_mapped_cat.shape, brfss_2015_mapped_cat.shape\n",
    ")\n",
    "\n",
    "brfss_2021_one_hot = pd.read_csv('BRFSS Datasets - Cleaned/One hot encoded (Step 3)/BRFSS 2021.csv')\n",
    "brfss_2019_one_hot = pd.read_csv('BRFSS Datasets - Cleaned/One hot encoded (Step 3)/BRFSS 2019.csv')\n",
    "brfss_2017_one_hot = pd.read_csv('BRFSS Datasets - Cleaned/One hot encoded (Step 3)/BRFSS 2017.csv')\n",
    "brfss_2015_one_hot = pd.read_csv('BRFSS Datasets - Cleaned/One hot encoded (Step 3)/BRFSS 2015.csv')\n",
    "\n",
    "print(brfss_2021_one_hot.shape, brfss_2019_one_hot.shape, brfss_2017_one_hot.shape, brfss_2015_one_hot.shape)\n",
    "\n",
    "brfss_2021_one_hot['Race'] = brfss_2021_mapped_cat['Race'] # this is added to test performance over race\n",
    "brfss_2019_one_hot['Race'] = brfss_2019_mapped_cat['Race'] # this is added to test performance over race\n",
    "brfss_2017_one_hot['Race'] = brfss_2017_mapped_cat['Race'] # this is added to test performance over race\n",
    "brfss_2015_one_hot['Race'] = brfss_2015_mapped_cat['Race'] # this is added to test performance over race\n",
    "\n",
    "print(brfss_2021_one_hot.shape, brfss_2019_one_hot.shape, brfss_2017_one_hot.shape, brfss_2015_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "brfss_2021_mapped_cat.groupby([\"Diabetes\", \"Age\"]).size().reset_index().to_csv(\"ML4H 23 (Submission files)/Code/Group Sample Count/BRFSS - 2021 - Diabetes-age.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performace_metrix(y_true, y_pred, y_pred_proba, group = \"whole\", disp = False):\n",
    "  # Assuming you have true labels y_true and predicted labels y_pred\n",
    "  # For class 0 and class 1\n",
    "\n",
    "  #y_true, y_pred = y_test_2021, pred_test_2021_lr\n",
    "\n",
    "  # Calculate precision, recall, and f1-score for each class\n",
    "  precision_0 = precision_score(y_true, y_pred, pos_label=0)\n",
    "  precision_1 = precision_score(y_true, y_pred, pos_label=1)\n",
    "\n",
    "  recall_0 = recall_score(y_true, y_pred, pos_label=0)\n",
    "  recall_1 = recall_score(y_true, y_pred, pos_label=1)\n",
    "\n",
    "  f1_0 = f1_score(y_true, y_pred, pos_label=0)\n",
    "  f1_1 = f1_score(y_true, y_pred, pos_label=1)\n",
    "\n",
    "  # Calculate Area Under the Precision-Recall Curve for each class\n",
    "  ap_0 = average_precision_score(y_true, y_pred_proba, pos_label=0)\n",
    "  ap_1 = average_precision_score(y_true, y_pred_proba, pos_label=1)\n",
    "\n",
    "  # Calculate overall accuracy\n",
    "  accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "  # Calculate balanced accuracy\n",
    "  balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "  # Calculate Area Under the ROC Curve\n",
    "  roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "\n",
    "  # Calculate Matthews Correlation Coefficient (MCC)\n",
    "  mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "  if disp == True:\n",
    "    # Print the calculated metrics\n",
    "    print(\"Class 1 Recall:\", recall_1)\n",
    "    print(\"Class 1 Precision:\", precision_1)\n",
    "    print(\"Class 1 Area Under Precision-Recall Curve:\", ap_1)\n",
    "    print(\"Class 1 F1-Score:\", f1_1)\n",
    "\n",
    "\n",
    "    print(\"Class 0 Recall:\", recall_0)\n",
    "    print(\"Class 0 Precision:\", precision_0)\n",
    "    print(\"Class 0 Area Under Precision-Recall Curve:\", ap_0)\n",
    "    print(\"Class 0 F1-Score:\", f1_0)\n",
    "\n",
    "    print(\"Overall Accuracy:\", accuracy)\n",
    "    print(\"Balanced Accuracy:\", balanced_accuracy)\n",
    "    print(\"Area Under ROC Curve:\", roc_auc)\n",
    "    print(\"Matthews Correlation Coefficient:\", mcc)\n",
    "\n",
    "\n",
    "    # Print the calculated metrics\n",
    "    print(recall_1)\n",
    "    print(precision_1)\n",
    "    print(ap_1)\n",
    "    print(f1_1)\n",
    "\n",
    "    print(recall_0)\n",
    "    print(precision_0)\n",
    "    print(ap_0)\n",
    "    print(f1_0)\n",
    "\n",
    "    print(accuracy)\n",
    "    print(balanced_accuracy)\n",
    "    print(roc_auc)\n",
    "    print(mcc)\n",
    "\n",
    "\n",
    "  performance = [group, recall_1, precision_1, ap_1, f1_1, recall_0, precision_0, ap_0, f1_0, accuracy, balanced_accuracy, roc_auc, mcc]\n",
    "  return performance\n",
    "\n",
    "def inset_performance_dict(performance_dict, performance):\n",
    "    c = 0\n",
    "    for k in performance_dict.keys():\n",
    "        performance_dict[k].append(performance[c])\n",
    "        c+=1\n",
    "    return performance_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.isotonic import IsotonicRegression as IR\n",
    "\n",
    "def isotonic(preds, labels, test_preds):\n",
    "    preds = np.array(preds)\n",
    "    labels = np.array(labels)\n",
    "    test_preds = np.array(test_preds)\n",
    "\n",
    "    ir = IR(out_of_bounds='clip')\n",
    "    ir.fit( preds, labels )\n",
    "\n",
    "    p_calibrated_v = ir.transform( preds )\n",
    "    p_calibrated_t = ir.transform( test_preds )   # or ir.fit( p_test ), that's the same thing\n",
    "\n",
    "    return p_calibrated_v, p_calibrated_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def Select_Threshold(df):\n",
    "    full_threshold_list = []\n",
    "    for threshold in np.arange(0,1.05,0.05):\n",
    "        #df.drop(columns = ['y_pred'])\n",
    "        df['y_pred'] = df['calibrated_prediction_prob'].apply(lambda x: 1 if x >= threshold else 0)\n",
    "        \n",
    "        y_pred = df[\"y_pred\"].values\n",
    "        y_true = df[\"y_true\"].values\n",
    "        \n",
    "        f1_C1 = f1_score(y_true, y_pred)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "        \n",
    "        full_threshold_list.append([threshold, f1_C1, balanced_accuracy])\n",
    "        \n",
    "    df_varying_threshold = pd.DataFrame(full_threshold_list, columns = ['threshold', 'f1_score', 'balanced_accuracy'])\n",
    "    \n",
    "    # select three highest F1 score and the the highest balanced accuracy\n",
    "    f1_scores = df_varying_threshold[\"f1_score\"].values\n",
    "    thresholds = df_varying_threshold[\"threshold\"].values\n",
    "    bal_acc_values = list(df_varying_threshold[\"balanced_accuracy\"].values)\n",
    "    \n",
    "    #print(heapq.nlargest(3, f1_scores))\n",
    "    list_index = heapq.nlargest(3, range(len(f1_scores)), key=f1_scores.__getitem__)\n",
    "    opt_threshold = thresholds[bal_acc_values.index(max(bal_acc_values[list_index[0]], bal_acc_values[list_index[1]], bal_acc_values[list_index[2]]))]\n",
    "    \n",
    "    \n",
    "    return opt_threshold, df_varying_threshold\n",
    "\n",
    "def pred_label_using_threshold(y_pred_p, th = 0.195):\n",
    "    y_pred_label = []\n",
    "    for y in y_pred_p:\n",
    "        if y <= th:\n",
    "            y_pred_label.append(0)\n",
    "        else:\n",
    "            y_pred_label.append(1)\n",
    "    return np.array(y_pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Model on BRFSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_result(X_train, y_train, \n",
    "                         X_test, y_test, \n",
    "                         X_validation, y_validation,\n",
    "                         df_test, \n",
    "                         save_dir = \"Performance/\",\n",
    "                         model_name = \"LR\",\n",
    "                         resampling = \"No_sampling\"):\n",
    "    \n",
    "    \n",
    "    if resampling == \"ENN\":\n",
    "      sampler = EditedNearestNeighbours(sampling_strategy='auto', n_neighbors=3)\n",
    "    elif resampling == \"NearMiss\":\n",
    "      sampler = NearMiss(sampling_strategy='auto', version=1)\n",
    "    elif resampling == \"SMOTE\":\n",
    "      sampler = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    elif resampling == \"RandomUnderSample\":\n",
    "      sampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "    elif resampling == \"SMOTEENN\":\n",
    "      smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "      sampler = SMOTEENN(sampling_strategy='auto', smote=smote, random_state=42)\n",
    "    elif resampling == \"TomekLinks\":\n",
    "      sampler = TomekLinks(sampling_strategy='auto')\n",
    "    elif resampling == \"ADASYN\":\n",
    "      sampler = ADASYN(sampling_strategy='auto')\n",
    "    elif resampling == \"RandomOverSample\":\n",
    "      sampler = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "    if resampling != \"No_sampling\":\n",
    "      X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    #print(\"Resampling\", resampling)\n",
    "\n",
    "    # train model\n",
    "    if model_name == \"LR\":\n",
    "      model = LogisticRegression(solver='liblinear')\n",
    "    elif model_name == \"RF\":\n",
    "      model = RandomForestClassifier()\n",
    "    elif model_name == \"SVM\":\n",
    "      model = SVC(probability=True, kernel='rbf', max_iter = 100)\n",
    "    elif model_name == \"KNN\":\n",
    "      model = KNeighborsClassifier(n_neighbors=5)\n",
    "    elif model_name == \"MLP\":\n",
    "      model = MLPClassifier()\n",
    "    elif model_name == \"NB\":\n",
    "      model = GaussianNB()\n",
    "    elif model_name == \"AdaBoost\":\n",
    "      model = AdaBoostClassifier(n_estimators=100, algorithm=\"SAMME\", random_state=0)\n",
    "    else:\n",
    "      model = LogisticRegression(solver='liblinear')\n",
    "    \n",
    "    #print(\"model selected:\", model_name)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # model predictions\n",
    "    pred_prob_test_lr = model.predict_proba(X_test)[:, 1]\n",
    "    pred_prob_validation_lr = model.predict_proba(X_validation)[:, 1]\n",
    "        \n",
    "    # model calibration\n",
    "    ir = IR(out_of_bounds='clip')\n",
    "    ir.fit(pred_prob_validation_lr, y_validation )\n",
    "    pred_prob_validation_lr_calibrated = ir.transform( pred_prob_validation_lr )\n",
    "    pred_prob_test_lr_calibrated = ir.transform( pred_prob_test_lr )\n",
    "\n",
    "    # threshold selection\n",
    "    val_preds = pd.DataFrame()\n",
    "    val_preds['y_true'] = y_validation\n",
    "    val_preds['calibrated_prediction_prob'] = pred_prob_validation_lr_calibrated\n",
    "    threshold_val, _ = Select_Threshold(val_preds)\n",
    "    #print(\"selected threshold:\", threshold_val)\n",
    "    \n",
    "    # threshold based labeling\n",
    "    pred_test_lr = pred_label_using_threshold(pred_prob_test_lr_calibrated, threshold_val)\n",
    "    \n",
    "\n",
    "    performance_dict = {\n",
    "        \"Group \": [],\n",
    "        \"Class 1 Recall\": [],\n",
    "        \"Class 1 Precision\": [],\n",
    "        \"Class 1 AU_PRC\": [],\n",
    "        \"Class 1 F1-Score\": [],\n",
    "        \"Class 0 Recall\": [],\n",
    "        \"Class 0 Precision\": [],\n",
    "        \"Class 0 AU_PRC\": [],\n",
    "        \"Class 0 F1-Score\": [],\n",
    "        \"Overall Accuracy\": [],\n",
    "        \"Balanced Accuracy\": [],\n",
    "        \"AU_ROC\": [],\n",
    "        \"MCC\": []\n",
    "    }\n",
    "\n",
    "    #print(\"============================ \", \"Over all performance\" , \"============================ \")\n",
    "    performance = performace_metrix(y_test, pred_test_lr, pred_prob_test_lr_calibrated, \"Whole\")\n",
    "    performance_dict = inset_performance_dict(performance_dict, performance)\n",
    "\n",
    "    # df_test contains \"Race\" column which is only required for group performance mapping\n",
    "    test = df_test.copy()\n",
    "\n",
    "    for i in range(1,3):\n",
    "      if (i == 1):\n",
    "        group = \"Male\"\n",
    "        #print(\"============================ \", \"Male\" , \"============================ \")\n",
    "      else:\n",
    "        group = \"Female\"\n",
    "        #print(\"============================ \", \"Female\" , \"============================ \")\n",
    "\n",
    "      test_group = test[test.Sex == i]\n",
    "\n",
    "      X_test_group = test_group.drop(['Diabetes', 'Race'],axis=1)\n",
    "      y_test_group = test_group['Diabetes']\n",
    "      y_test_group = y_test_group.to_numpy()\n",
    "\n",
    "      #pred_test_group = lr.predict(X_test_group)\n",
    "      pred_prob_test_group = model.predict_proba(X_test_group)[:, 1]\n",
    "      \n",
    "      #calibration\n",
    "      pred_prob_test_group_calibrated = ir.transform( pred_prob_test_group )\n",
    "    \n",
    "      # thresholding\n",
    "      pred_test_group = pred_label_using_threshold(pred_prob_test_group_calibrated, threshold_val)\n",
    "\n",
    "      performance = performace_metrix(y_test_group, pred_test_group, pred_prob_test_group, group)\n",
    "      performance_dict = inset_performance_dict(performance_dict, performance)\n",
    "\n",
    "\n",
    "    race_list = ['White', 'Black','American Indian', 'Asian', 'Native Hawaiian',\n",
    "                 'Other race', 'Multiracial', 'Hispanic']\n",
    "\n",
    "    for i in race_list:\n",
    "      test_group = test[test.Race == i]\n",
    "      #print(\"============================ \", i , \"============================ \")\n",
    "\n",
    "      X_test_group = test_group.drop(['Diabetes', 'Race'],axis=1)\n",
    "      y_test_group = test_group['Diabetes']\n",
    "      y_test_group = y_test_group.to_numpy()\n",
    "\n",
    "      #pred_test_group = lr.predict(X_test_group)\n",
    "      pred_prob_test_group = model.predict_proba(X_test_group)[:, 1]\n",
    "    \n",
    "      #calibration\n",
    "      pred_prob_test_group_calibrated = ir.transform( pred_prob_test_group )\n",
    "    \n",
    "      # thresholding\n",
    "      pred_test_group = pred_label_using_threshold(pred_prob_test_group_calibrated, threshold_val)\n",
    "\n",
    "      performance = performace_metrix(y_test_group, pred_test_group, pred_prob_test_group, i)\n",
    "      performance_dict = inset_performance_dict(performance_dict, performance)\n",
    "\n",
    "\n",
    "    age_group = {3: '30-34', 4: '35-39', 5: '40-44', 6: '45-49',\n",
    "                 7: '50-54', 8: '55-59', 9: '60-64', 10: '65-69',\n",
    "                 11: '70-74', 12: '75-79', 13: '80-99'}\n",
    "\n",
    "    for i in age_group.keys():\n",
    "      test_group = test[test.Age == i]\n",
    "      #print(\"============================ \", age_group[i] , \"============================ \")\n",
    "\n",
    "      X_test_group = test_group.drop(['Diabetes', 'Race'],axis=1)\n",
    "      y_test_group = test_group['Diabetes']\n",
    "      y_test_group = y_test_group.to_numpy()\n",
    "\n",
    "      #pred_test_group = lr.predict(X_test_group)\n",
    "      pred_prob_test_group = model.predict_proba(X_test_group)[:, 1]\n",
    "    \n",
    "      #calibration\n",
    "      pred_prob_test_group_calibrated = ir.transform( pred_prob_test_group )\n",
    "    \n",
    "      # thresholding\n",
    "      pred_test_group = pred_label_using_threshold(pred_prob_test_group_calibrated, threshold_val)\n",
    "\n",
    "      performace = performace_metrix(y_test_group, pred_test_group, pred_prob_test_group, age_group[i])\n",
    "      performance_dict = inset_performance_dict(performance_dict, performace)\n",
    "\n",
    "    all_performances = pd.DataFrame(performance_dict)\n",
    "    all_performances.to_csv(save_dir + model_name + \"_\" + resampling   +  \".csv\", index=False)\n",
    "    \n",
    "    return all_performances\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data split for entire experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200136, 50) (120081, 50) (40027, 50) (40028, 50)\n",
      "(120081, 48) (40027, 48) (40028, 48)\n"
     ]
    }
   ],
   "source": [
    "random_state = 1\n",
    "df_train_2021, df_test_2021 = train_test_split(brfss_2021_one_hot, test_size=0.4, random_state=random_state)\n",
    "df_test_2021, df_validation_2021 = train_test_split(df_test_2021, test_size=0.5, random_state=random_state)\n",
    "print(brfss_2021_one_hot.shape, df_train_2021.shape, df_test_2021.shape, df_validation_2021.shape)\n",
    "\n",
    "X_train_2021 = df_train_2021.drop(['Diabetes', 'Race'],axis=1)\n",
    "y_train_2021 = df_train_2021['Diabetes']\n",
    "\n",
    "X_test_2021 = df_test_2021.drop(['Diabetes', 'Race'],axis=1)\n",
    "y_test_2021 = df_test_2021['Diabetes']\n",
    "y_test_2021 = y_test_2021.to_numpy()\n",
    "\n",
    "X_validation_2021 = df_validation_2021.drop(['Diabetes', 'Race'],axis=1)\n",
    "y_validation_2021 = df_validation_2021['Diabetes']\n",
    "y_validation_2021 = y_validation_2021.to_numpy()\n",
    "\n",
    "print(X_train_2021.shape, X_test_2021.shape, X_validation_2021.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220390, 50) (132234, 50) (44078, 50) (44078, 50)\n",
      "(132234, 48) (44078, 48) (44078, 48)\n"
     ]
    }
   ],
   "source": [
    "random_state = 1\n",
    "df_train_2015, df_test_2015 = train_test_split(brfss_2015_one_hot, test_size=0.4, random_state=random_state)\n",
    "df_test_2015, df_validation_2015 = train_test_split(df_test_2015, test_size=0.5, random_state=random_state)\n",
    "print(brfss_2015_one_hot.shape, df_train_2015.shape, df_test_2015.shape, df_validation_2015.shape)\n",
    "\n",
    "X_train_2015 = df_train_2015.drop(['Diabetes', 'Race'],axis=1)\n",
    "y_train_2015 = df_train_2015['Diabetes']\n",
    "\n",
    "X_test_2015 = df_test_2015.drop(['Diabetes', 'Race'],axis=1)\n",
    "y_test_2015 = df_test_2015['Diabetes']\n",
    "y_test_2015 = y_test_2015.to_numpy()\n",
    "\n",
    "X_validation_2015 = df_validation_2015.drop(['Diabetes', 'Race'],axis=1)\n",
    "y_validation_2015 = df_validation_2015['Diabetes']\n",
    "y_validation_2015 = y_validation_2015.to_numpy()\n",
    "\n",
    "print(X_train_2015.shape, X_test_2015.shape, X_validation_2015.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age Based Subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "age_group_map = {\n",
    "    3:\t'30-34',\n",
    "    4:\t'35-39',\n",
    "    5:\t'40-44',\n",
    "    6:\t'45-49',\n",
    "    7:\t'50-54',\n",
    "    8:\t'55-59',\n",
    "    9:\t'60-64',\n",
    "    10:\t'65-69',\n",
    "    11:\t'70-74',\n",
    "    12:\t'75-79',\n",
    "    13:\t'80-99'\n",
    "}\n",
    "\n",
    "for age_group in age_group_map.keys():\n",
    "    print(\"===========================\", age_group_map[age_group], \"===========================\")\n",
    "\n",
    "    Train_age_3_df = df_train_2021[df_train_2021['Age'] == age_group]\n",
    "    Validation_age_3_df = df_validation_2021[df_validation_2021['Age'] == age_group]\n",
    "    Test_age_3_df = df_test_2021[df_test_2021['Age'] == age_group]\n",
    "\n",
    "    print(Train_age_3_df.shape, Validation_age_3_df.shape, Test_age_3_df.shape)\n",
    "\n",
    "    X_train = Train_age_3_df.drop(['Diabetes', 'Race'],axis=1)\n",
    "    y_train = Train_age_3_df['Diabetes']\n",
    "\n",
    "    X_test = Test_age_3_df.drop(['Diabetes', 'Race'],axis=1)\n",
    "    y_test = Test_age_3_df['Diabetes']\n",
    "\n",
    "    X_val = Validation_age_3_df.drop(['Diabetes', 'Race'],axis=1)\n",
    "    y_val = Validation_age_3_df['Diabetes']\n",
    "\n",
    "\n",
    "    print(X_train.shape, X_train.shape, X_test.shape)\n",
    "\n",
    "    model_names = [\"LR\", \"RF\", \"SVM\", \"KNN\", \"MLP\", \"NB\", \"AdaBoost\"]\n",
    "    resamplings = [\"ENN\", \"NearMiss\", \"SMOTE\", \"RandomUnderSample\", \"SMOTEENN\", \"TomekLinks\", \"ADASYN\", \"RandomOverSample\", \"No_sampling\"]\n",
    "\n",
    "    directory = \"ML4H 23 (Submission files)/Code/Subgroup_separate_training/BRFSS_2021/Age/\" + age_group_map[age_group] + \"/\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    for model_name in model_names:\n",
    "        for resampling in resamplings:\n",
    "\n",
    "            train_test_result(X_train, y_train, \n",
    "                                X_test, y_test,  \n",
    "                                X_val, y_val,\n",
    "                                df_test_2021,\n",
    "                                save_dir = directory,\n",
    "                                model_name = model_name,\n",
    "                                resampling = resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================== 30-44 ===========================\n",
      "(24399, 50) (8214, 50) (8177, 50)\n",
      "(24399, 48) (24399, 48) (8177, 48)\n",
      "=========================== 45-59 ===========================\n",
      "(34452, 50) (11339, 50) (11400, 50)\n",
      "(34452, 48) (34452, 48) (11400, 48)\n",
      "=========================== 60-74 ===========================\n",
      "(43925, 50) (14745, 50) (14649, 50)\n",
      "(43925, 48) (43925, 48) (14649, 48)\n",
      "=========================== 75-99 ===========================\n",
      "(17305, 50) (5730, 50) (5801, 50)\n",
      "(17305, 48) (17305, 48) (5801, 48)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "age_group_map = {\n",
    "    '30-44': [3, 4, 5],\n",
    "    '45-59': [6, 7, 8],\n",
    "    '60-74': [9, 10, 11],\n",
    "    '75-99': [12, 13]\n",
    "}\n",
    "\n",
    "\n",
    "for age_group in age_group_map.keys():\n",
    "    print(\"===========================\", age_group, \"===========================\")\n",
    "\n",
    "    Train_age_3_df = df_train_2021[df_train_2021['Age'].isin(age_group_map[age_group])]\n",
    "    Validation_age_3_df = df_validation_2021[df_validation_2021['Age'].isin(age_group_map[age_group])]\n",
    "    Test_age_3_df = df_test_2021[df_test_2021['Age'].isin(age_group_map[age_group])]\n",
    "\n",
    "    print(Train_age_3_df.shape, Validation_age_3_df.shape, Test_age_3_df.shape)\n",
    "\n",
    "    X_train = Train_age_3_df.drop(['Diabetes', 'Race'],axis=1)\n",
    "    y_train = Train_age_3_df['Diabetes']\n",
    "\n",
    "    X_test = Test_age_3_df.drop(['Diabetes', 'Race'],axis=1)\n",
    "    y_test = Test_age_3_df['Diabetes']\n",
    "\n",
    "    X_val = Validation_age_3_df.drop(['Diabetes', 'Race'],axis=1)\n",
    "    y_val = Validation_age_3_df['Diabetes']\n",
    "\n",
    "\n",
    "    print(X_train.shape, X_train.shape, X_test.shape)\n",
    "\n",
    "    model_names = [\"LR\", \"RF\", \"SVM\", \"KNN\", \"MLP\", \"NB\", \"AdaBoost\"]\n",
    "    resamplings = [\"ENN\", \"NearMiss\", \"SMOTE\", \"RandomUnderSample\", \"SMOTEENN\", \"TomekLinks\", \"ADASYN\", \"RandomOverSample\", \"No_sampling\"]\n",
    "\n",
    "    directory = \"ML4H 23 (Submission files)/Code/Subgroup_separate_training/BRFSS_2021/Age/span_15/\" + age_group + \"/\"\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    for model_name in model_names:\n",
    "        for resampling in resamplings:\n",
    "\n",
    "            train_test_result(X_train, y_train, \n",
    "                                X_test, y_test,  \n",
    "                                X_val, y_val,\n",
    "                                df_test_2021,\n",
    "                                save_dir = directory,\n",
    "                                model_name = model_name,\n",
    "                                resampling = resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "age_group_map = {\n",
    "    3:\t'30-34',\n",
    "    4:\t'35-39',\n",
    "    5:\t'40-44',\n",
    "    6:\t'45-49',\n",
    "    7:\t'50-54',\n",
    "    8:\t'55-59',\n",
    "    9:\t'60-64',\n",
    "    10:\t'65-69',\n",
    "    11:\t'70-74',\n",
    "    12:\t'75-79',\n",
    "    13:\t'80-99'\n",
    "}\n",
    "\n",
    "for age_group in age_group_map.keys():\n",
    "    print(\"===========================\", age_group_map[age_group], \"===========================\")\n",
    "\n",
    "    Train_age_3_df = df_train_2015[df_train_2015['Age'] == age_group]\n",
    "    Validation_age_3_df = df_validation_2015[df_validation_2015['Age'] == age_group]\n",
    "    Test_age_3_df = df_test_2015[df_test_2015['Age'] == age_group]\n",
    "\n",
    "    print(Train_age_3_df.shape, Validation_age_3_df.shape, Test_age_3_df.shape)\n",
    "\n",
    "    X_train = Train_age_3_df.drop(['Diabetes', 'Race'],axis=1)\n",
    "    y_train = Train_age_3_df['Diabetes']\n",
    "\n",
    "    X_test = Test_age_3_df.drop(['Diabetes', 'Race'],axis=1)\n",
    "    y_test = Test_age_3_df['Diabetes']\n",
    "\n",
    "    X_val = Validation_age_3_df.drop(['Diabetes', 'Race'],axis=1)\n",
    "    y_val = Validation_age_3_df['Diabetes']\n",
    "\n",
    "\n",
    "    print(X_train.shape, X_train.shape, X_test.shape)\n",
    "\n",
    "    model_names = [\"LR\", \"RF\", \"SVM\", \"KNN\", \"MLP\", \"NB\", \"AdaBoost\"]\n",
    "    resamplings = [\"ENN\", \"NearMiss\", \"SMOTE\", \"RandomUnderSample\", \"SMOTEENN\", \"TomekLinks\", \"ADASYN\", \"RandomOverSample\", \"No_sampling\"]\n",
    "\n",
    "    directory = \"ML4H 23 (Submission files)/Code/Subgroup_separate_training/BRFSS_2015/Age/\" + age_group_map[age_group] + \"/\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    for model_name in model_names:\n",
    "        for resampling in resamplings:\n",
    "\n",
    "            train_test_result(X_train, y_train, \n",
    "                                X_test, y_test,  \n",
    "                                X_val, y_val,\n",
    "                                df_test_2015,\n",
    "                                save_dir = directory,\n",
    "                                model_name = model_name,\n",
    "                                resampling = resampling)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================== 30-44 ===========================\n",
      "(22096, 50) (7572, 50) (7479, 50)\n",
      "(22096, 48) (22096, 48) (7479, 48)\n",
      "=========================== 45-59 ===========================\n",
      "(42454, 50) (13994, 50) (14122, 50)\n",
      "(42454, 48) (42454, 48) (14122, 48)\n",
      "=========================== 60-74 ===========================\n",
      "(49465, 50) (16379, 50) (16434, 50)\n",
      "(49465, 48) (49465, 48) (16434, 48)\n",
      "=========================== 75-99 ===========================\n",
      "(18219, 50) (6133, 50) (6043, 50)\n",
      "(18219, 48) (18219, 48) (6043, 48)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "age_group_map = {\n",
    "    '30-44': [3, 4, 5],\n",
    "    '45-59': [6, 7, 8],\n",
    "    '60-74': [9, 10, 11],\n",
    "    '75-99': [12, 13]\n",
    "}\n",
    "\n",
    "\n",
    "for age_group in age_group_map.keys():\n",
    "    print(\"===========================\", age_group, \"===========================\")\n",
    "\n",
    "    Train_age_3_df = df_train_2015[df_train_2015['Age'].isin(age_group_map[age_group])]\n",
    "    Validation_age_3_df = df_validation_2015[df_validation_2015['Age'].isin(age_group_map[age_group])]\n",
    "    Test_age_3_df = df_test_2015[df_test_2015['Age'].isin(age_group_map[age_group])]\n",
    "\n",
    "    print(Train_age_3_df.shape, Validation_age_3_df.shape, Test_age_3_df.shape)\n",
    "\n",
    "    X_train = Train_age_3_df.drop(['Diabetes', 'Race'],axis=1)\n",
    "    y_train = Train_age_3_df['Diabetes']\n",
    "\n",
    "    X_test = Test_age_3_df.drop(['Diabetes', 'Race'],axis=1)\n",
    "    y_test = Test_age_3_df['Diabetes']\n",
    "\n",
    "    X_val = Validation_age_3_df.drop(['Diabetes', 'Race'],axis=1)\n",
    "    y_val = Validation_age_3_df['Diabetes']\n",
    "\n",
    "\n",
    "    print(X_train.shape, X_train.shape, X_test.shape)\n",
    "\n",
    "    model_names = [\"LR\", \"RF\", \"SVM\", \"KNN\", \"MLP\", \"NB\", \"AdaBoost\"]\n",
    "    resamplings = [\"ENN\", \"NearMiss\", \"SMOTE\", \"RandomUnderSample\", \"SMOTEENN\", \"TomekLinks\", \"ADASYN\", \"RandomOverSample\", \"No_sampling\"]\n",
    "\n",
    "    directory = \"ML4H 23 (Submission files)/Code/Subgroup_separate_training/BRFSS_2015/Age/span_15/\" + age_group + \"/\"\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    for model_name in model_names:\n",
    "        for resampling in resamplings:\n",
    "\n",
    "            train_test_result(X_train, y_train, \n",
    "                                X_test, y_test,  \n",
    "                                X_val, y_val,\n",
    "                                df_test_2015,\n",
    "                                save_dir = directory,\n",
    "                                model_name = model_name,\n",
    "                                resampling = resampling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
